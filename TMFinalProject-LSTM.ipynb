{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining Final Project 2019 - 2020 - LSTM\n",
    "\n",
    "## Identifying Authors by Their Writings \n",
    "\n",
    "## Authors: \n",
    "- Lara Neves (m20190867) \n",
    "- Susana Paço (m20190821)\n",
    "- Inês Diogo (m20190301)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to ease the weight on the main notebook, a separate notebook was created to keep the LSTM model and its needed pre processing. All of the preprocessing required follows the same functions as in the original notebook. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installs - please uncomment those packages that you don't have within your system in order to install them\n",
    "\n",
    "import sys\n",
    "#!{sys.executable} -m pip install -U unidecode\n",
    "#!{sys.executable} -m pip install -U keras\n",
    "#!{sys.executable} -m pip install -U tensorflow\n",
    "#!{sys.executable} -m pip install -U nltk\n",
    "#!{sys.executable} -m pip install git+https://github.com/textpipe/textpipe.git\n",
    "#!{sys.executable} -m pip install -U spacy\n",
    "#!{sys.executable} -m  spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"DPP\">\n",
    "\n",
    "## 1. Data Preprocessing\n",
    "\n",
    "</a>\n",
    "\n",
    "\n",
    "<a class=\"anchor\" id=\"rename\">\n",
    "\n",
    "### 1.1. Renaming .txt Files\n",
    "</a>\n",
    "   \n",
    "We will start by renaming the .txt files so there's no duplicates and we create a standardized form to \n",
    "identify each .txt file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the names of the .txt files so there's no duplicates and we create a standardized form to \n",
    "#identify each .txt\n",
    "\n",
    "def change_file_name(author):\n",
    "    i = 0\n",
    "    my_dir_path = \"Data/Corpora/train/\" + author\n",
    "    \n",
    "    for filename in os.listdir(my_dir_path): \n",
    "        \n",
    "        #Define the new and old names with directory path\n",
    "        new_name =str(author) + str(i) + \".txt\"\n",
    "        old_name = my_dir_path + '/' + filename \n",
    "        new_name = my_dir_path + '/' + new_name \n",
    "        \n",
    "        #So it doesn't give out an error when it runs for the second time\n",
    "        # rename all the files \n",
    "        if new_name != old_name: #IT STILL GIVES OUT ERROR\n",
    "            os.rename(old_name, new_name) \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = ['AlmadaNegreiros','CamiloCasteloBranco','EcaDeQueiros','JoseRodriguesSantos','JoseSaramago','LuisaMarquesSilva']\n",
    "authors_sigla = ['AN','CCB','EQ','JRS','JS','LMS']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ONLY RUN ONCE IF THE FILE NAMES ARE THE ORIGINAL otherwise, running a second time, will give an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for a in range(len(authors)):\n",
    "#    change_file_name(authors[a])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"extract\">\n",
    "\n",
    "### 1.2. Extracting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a df for one author the respective .txt files in the corpora\n",
    "def create_df_from_txt(author):\n",
    "    my_dir_path = \"Data/Corpora/train/\" + author\n",
    "\n",
    "    results = defaultdict(list)\n",
    "    for file in Path(my_dir_path).iterdir():\n",
    "        with open(file, \"r\",encoding = 'utf8') as file_open:\n",
    "            results[\"id\"].append(file.name)\n",
    "            results[\"text\"].append(file_open.read())\n",
    "            results[\"author\"] = author\n",
    "            file_open.close()\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join together the dataframes from all the authors\n",
    "def join_df(authors):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for a in range(len(authors)):\n",
    "        df = df.append(create_df_from_txt(authors[a]))\n",
    "    df.reset_index(inplace = True, drop = True)    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AlmadaNegreiros3.txt</td>\n",
       "      <td>\\nTitle: Litoral\\n       A Amadeo de Souza Car...</td>\n",
       "      <td>AN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AlmadaNegreiros2.txt</td>\n",
       "      <td>\\n\\nTitle: A Invenção do Dia Claro\\n\\nAuthor: ...</td>\n",
       "      <td>AN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AlmadaNegreiros0.txt</td>\n",
       "      <td>Title: A Scena do Odio\\n\\nAuthor: José de Alma...</td>\n",
       "      <td>AN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AlmadaNegreiros1.txt</td>\n",
       "      <td>Title: O Jardim da Pierrette\\n\\nAuthor: José d...</td>\n",
       "      <td>AN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AlmadaNegreiros5.txt</td>\n",
       "      <td>\\n\\n*JOSÉ DE ALMADA-NEGREIROS*\\n\\n\\n*K4\\n\\no q...</td>\n",
       "      <td>AN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>LuisaMarquesSilva3.txt</td>\n",
       "      <td>CONTROL Z\\nChegou a hora de vos contar. Chegou...</td>\n",
       "      <td>LMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>LuisaMarquesSilva2.txt</td>\n",
       "      <td>O terrível caso do botão assassino\\nLuísa Marq...</td>\n",
       "      <td>LMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>LuisaMarquesSilva0.txt</td>\n",
       "      <td>A BELA HISTÓRIA DE DINIS E BEATRIZ OU REQUIEM ...</td>\n",
       "      <td>LMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>LuisaMarquesSilva1.txt</td>\n",
       "      <td>\\n\\n\\nAcabou-se!\\nLuísa Marques da Silva\\n\\nTí...</td>\n",
       "      <td>LMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>LuisaMarquesSilva8.txt</td>\n",
       "      <td>Título\\nA última história\\n\\nAutora (próximo N...</td>\n",
       "      <td>LMS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                               text  \\\n",
       "0     AlmadaNegreiros3.txt  \\nTitle: Litoral\\n       A Amadeo de Souza Car...   \n",
       "1     AlmadaNegreiros2.txt  \\n\\nTitle: A Invenção do Dia Claro\\n\\nAuthor: ...   \n",
       "2     AlmadaNegreiros0.txt  Title: A Scena do Odio\\n\\nAuthor: José de Alma...   \n",
       "3     AlmadaNegreiros1.txt  Title: O Jardim da Pierrette\\n\\nAuthor: José d...   \n",
       "4     AlmadaNegreiros5.txt  \\n\\n*JOSÉ DE ALMADA-NEGREIROS*\\n\\n\\n*K4\\n\\no q...   \n",
       "..                     ...                                                ...   \n",
       "58  LuisaMarquesSilva3.txt  CONTROL Z\\nChegou a hora de vos contar. Chegou...   \n",
       "59  LuisaMarquesSilva2.txt  O terrível caso do botão assassino\\nLuísa Marq...   \n",
       "60  LuisaMarquesSilva0.txt  A BELA HISTÓRIA DE DINIS E BEATRIZ OU REQUIEM ...   \n",
       "61  LuisaMarquesSilva1.txt  \\n\\n\\nAcabou-se!\\nLuísa Marques da Silva\\n\\nTí...   \n",
       "62  LuisaMarquesSilva8.txt  Título\\nA última história\\n\\nAutora (próximo N...   \n",
       "\n",
       "   author  \n",
       "0      AN  \n",
       "1      AN  \n",
       "2      AN  \n",
       "3      AN  \n",
       "4      AN  \n",
       "..    ...  \n",
       "58    LMS  \n",
       "59    LMS  \n",
       "60    LMS  \n",
       "61    LMS  \n",
       "62    LMS  \n",
       "\n",
       "[63 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Running all the functions\n",
    "\n",
    "#Creating the training data frame\n",
    "traindf = join_df(authors)\n",
    "\n",
    "#Replacing the name of the authors with labels of their initials\n",
    "for i in range(0,len(authors)):\n",
    "    traindf.author = traindf.author.replace(authors[i],authors_sigla[i])\n",
    "traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a df for one author the respective .txt files in the corpora\n",
    "def create_df_from_txttest(numberofwords):\n",
    "    my_dir_path = \"Data/Corpora/test/\"+ str(numberofwords)\n",
    "\n",
    "    results = defaultdict(list)\n",
    "    for file in Path(my_dir_path).iterdir():\n",
    "        with open(file, \"r\",encoding = 'utf8') as file_open:\n",
    "            results[\"id\"].append(file.name)\n",
    "            results[\"text\"].append(file_open.read())\n",
    "            results[\"numberofwords\"] = numberofwords\n",
    "            file_open.close()\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_dftest(numberofwords):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for a in range(len(numberofwords)):\n",
    "        df = df.append(create_df_from_txttest(numberofwords[a]))\n",
    "    df.reset_index(inplace = True, drop = True)    \n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberofwords = [1000, 500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Running all the functions\n",
    "\n",
    "#Creating the training data frame\n",
    "testdf = join_dftest(numberofwords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>numberofwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text6.txt</td>\n",
       "      <td>\"O Senhor ensina pela pena o que o homem não s...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text5.txt</td>\n",
       "      <td>O cahos de cima a descer, a descer com a morta...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text4.txt</td>\n",
       "      <td>Agora, porém, era sem fervor, arrastadamente, ...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text1.txt</td>\n",
       "      <td>Depois, pouco a pouco, a tranquilidade regress...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text3.txt</td>\n",
       "      <td>Quase um mês depois, a época de exames aproxim...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>text2.txt</td>\n",
       "      <td>Justamente como se eu tivesse tido a ideia de ...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>text6.txt</td>\n",
       "      <td>\"O Senhor ensina pela pena o que o homem não s...</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>text5.txt</td>\n",
       "      <td>O cahos de cima a descer, a descer com a morta...</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>text4.txt</td>\n",
       "      <td>Agora, porém, era sem fervor, arrastadamente, ...</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>text1.txt</td>\n",
       "      <td>Depois, pouco a pouco, a tranquilidade regress...</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>text3.txt</td>\n",
       "      <td>Quase um mês depois, a época de exames aproxim...</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>text2.txt</td>\n",
       "      <td>Justamente como se eu tivesse tido a ideia de ...</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text  \\\n",
       "0   text6.txt  \"O Senhor ensina pela pena o que o homem não s...   \n",
       "1   text5.txt  O cahos de cima a descer, a descer com a morta...   \n",
       "2   text4.txt  Agora, porém, era sem fervor, arrastadamente, ...   \n",
       "3   text1.txt  Depois, pouco a pouco, a tranquilidade regress...   \n",
       "4   text3.txt  Quase um mês depois, a época de exames aproxim...   \n",
       "5   text2.txt  Justamente como se eu tivesse tido a ideia de ...   \n",
       "6   text6.txt  \"O Senhor ensina pela pena o que o homem não s...   \n",
       "7   text5.txt  O cahos de cima a descer, a descer com a morta...   \n",
       "8   text4.txt  Agora, porém, era sem fervor, arrastadamente, ...   \n",
       "9   text1.txt  Depois, pouco a pouco, a tranquilidade regress...   \n",
       "10  text3.txt  Quase um mês depois, a época de exames aproxim...   \n",
       "11  text2.txt  Justamente como se eu tivesse tido a ideia de ...   \n",
       "\n",
       "    numberofwords  \n",
       "0            1000  \n",
       "1            1000  \n",
       "2            1000  \n",
       "3            1000  \n",
       "4            1000  \n",
       "5            1000  \n",
       "6             500  \n",
       "7             500  \n",
       "8             500  \n",
       "9             500  \n",
       "10            500  \n",
       "11            500  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From analysis of the texts, these are the supposed y_test values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill a y_test column with possible answers\n",
    "\n",
    "\n",
    "\n",
    "testdf.loc[testdf['id'] == 'text1.txt', 'possibleanswer'] = 'JS'\n",
    "testdf.loc[testdf['id'] == 'text2.txt', 'possibleanswer'] = 'AN'\n",
    "testdf.loc[testdf['id'] == 'text3.txt', 'possibleanswer'] = 'unknown'\n",
    "testdf.loc[testdf['id'] == 'text4.txt', 'possibleanswer'] = 'EQ'\n",
    "testdf.loc[testdf['id'] == 'text5.txt', 'possibleanswer'] = 'CCB'\n",
    "testdf.loc[testdf['id'] == 'text6.txt', 'possibleanswer'] = 'JRS'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"clearMD\">\n",
    "\n",
    "### 1.2. Clearing MetaData\n",
    "</a>\n",
    "\n",
    "The majority of the .txt files have metadata at the beginning. This is unnecessary and may introduce noise in our model, as such it may be a good idea to remove it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#author names to remove them from metadata\n",
    "authors = [\"José de Almada Negreiros\", \"José de ALMADA-NEGREIROS\", \"JOSÉ DE ALMADA-NEGREIROS\", \"Almada Negreiros\", \"Camilo Castelo Branco\", \"CAMILLO CASTELLO BRANCO\", \"CAMILLO CASTELLO-BRANCO\", \"Camillo Castello Branco\", \"Eça de Queirós\", \"Eca de Queiros\", \"José Rodrigues dos Santos\",\"Jose Rodrigues dos Santos\", \"JOSÉ RODRIGUES DOS SANTOS\", \"José Saramago\", \"Jose Saramago\", \"JoSÉ SaRamago\", \"Luísa Marques Silva\", \"Luisa Marques Silva\", \"Luísa Marques da Silva\"]  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eça de Queirós</th>\n",
       "      <th>Camilo Castelo Branco</th>\n",
       "      <th>Almada Negreiros</th>\n",
       "      <th>Saramago</th>\n",
       "      <th>José Rodrigues dos Santos</th>\n",
       "      <th>Luísa Marques Silva</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O Mistério da Estrada de Sintra</td>\n",
       "      <td>Anátema</td>\n",
       "      <td>O Moinho</td>\n",
       "      <td>Terra do Pecado</td>\n",
       "      <td>Comunicação, Difusão Cultural, 1992; Prefácio</td>\n",
       "      <td>Acabou-se!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O Crime do Padre Amaro</td>\n",
       "      <td>Os Mistérios de Lisboa</td>\n",
       "      <td>Os Outros</td>\n",
       "      <td>Manual de Pintura e Caligrafia</td>\n",
       "      <td>Crónicas de Guerra I - Da Crimeia a Dachau</td>\n",
       "      <td>Sete Histórias por Acontecer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Tragédia da Rua das Flores</td>\n",
       "      <td>A Filha do Arcediago</td>\n",
       "      <td>23, 2º Andar</td>\n",
       "      <td>Levantado do Chão</td>\n",
       "      <td>Crónicas de Guerra II - De Saigão a Bagdade</td>\n",
       "      <td>e-Medo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Eça de Queirós   Camilo Castelo Branco Almada Negreiros  \\\n",
       "0  O Mistério da Estrada de Sintra                 Anátema         O Moinho   \n",
       "1           O Crime do Padre Amaro  Os Mistérios de Lisboa        Os Outros   \n",
       "2     A Tragédia da Rua das Flores    A Filha do Arcediago    23, 2º Andar    \n",
       "\n",
       "                         Saramago  \\\n",
       "0                 Terra do Pecado   \n",
       "1  Manual de Pintura e Caligrafia   \n",
       "2               Levantado do Chão   \n",
       "\n",
       "                       José Rodrigues dos Santos           Luísa Marques Silva  \n",
       "0  Comunicação, Difusão Cultural, 1992; Prefácio                    Acabou-se!  \n",
       "1     Crónicas de Guerra I - Da Crimeia a Dachau  Sete Histórias por Acontecer  \n",
       "2    Crónicas de Guerra II - De Saigão a Bagdade                        e-Medo  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#book names to stop words\n",
    "authorsandbooks = pd.read_excel('Data/AuthorsAndBooks.xlsx')\n",
    "authorsandbooks.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#authors work to arrays\n",
    "\n",
    "# Eça Queirós books\n",
    "Eca = authorsandbooks['Eça de Queirós']\n",
    "Eca = Eca.dropna()\n",
    "Eca = pd.array(Eca)\n",
    "\n",
    "\n",
    "#Camilo Castelo Branco books\n",
    "camilo = authorsandbooks['Camilo Castelo Branco']\n",
    "camilo = camilo.dropna()\n",
    "camilo = pd.array(camilo)\n",
    "\n",
    "\n",
    "# Almada Negreiros books\n",
    "Almada = authorsandbooks['Almada Negreiros']\n",
    "Almada = Almada.dropna()\n",
    "Almada = pd.array(Almada)\n",
    "\n",
    "\n",
    "# Saramago books\n",
    "Saramago = authorsandbooks['Saramago']\n",
    "Saramago = Saramago.dropna()\n",
    "Saramago = pd.array(Saramago)\n",
    "\n",
    "\n",
    "# José Rodrigues dos Santos books\n",
    "JRodriguesSantos = authorsandbooks['José Rodrigues dos Santos']\n",
    "JRodriguesSantos = JRodriguesSantos.dropna()\n",
    "JRodriguesSantos = pd.array(JRodriguesSantos)\n",
    "\n",
    "\n",
    "# Luísa Marques Silva books\n",
    "luisaMarquesSilva = authorsandbooks['Luísa Marques Silva']\n",
    "luisaMarquesSilva = luisaMarquesSilva.dropna()\n",
    "luisaMarquesSilva = pd.array(luisaMarquesSilva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm_notebook as tqdm #progressbar\n",
    "\n",
    "def removemetadata(doc):\n",
    "    processed_corpus = []\n",
    "    for i in tqdm(range(len(doc))):\n",
    "        text = doc['text'].iloc[i,]\n",
    "        for w in authors:\n",
    "            text = re.sub(w,\"\",text)\n",
    "        for x in Eca:\n",
    "            text = re.sub(x,\"\",text)\n",
    "        for t in camilo:\n",
    "            text = re.sub(t,\"\",text)\n",
    "        for s in Almada:\n",
    "            text = re.sub(s,\"\",text)\n",
    "        for y in Saramago:\n",
    "            text = re.sub(y,\"\",text)\n",
    "        for n in JRodriguesSantos:\n",
    "            text = re.sub(n,\"\",text)\n",
    "        for m in luisaMarquesSilva:\n",
    "            text = re.sub(m,\"\",text)\n",
    "        processed_corpus.append(text)\n",
    "    return processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d1581dbc6040a89a7f1cb705a24d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=63.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57524778d2c4fcfb05689785a3a3061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#create a column to test the results of removing crucial metadata text\n",
    "traindf['removeMetadata'] = removemetadata(traindf)\n",
    "testdf['removeMetadata'] = removemetadata(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>removeMetadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AlmadaNegreiros3.txt</td>\n",
       "      <td>\\nTitle: Litoral\\n       A Amadeo de Souza Car...</td>\n",
       "      <td>AN</td>\n",
       "      <td>\\nTitle: \\n       \\n\\nAuthor: \\n\\nContributor:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AlmadaNegreiros2.txt</td>\n",
       "      <td>\\n\\nTitle: A Invenção do Dia Claro\\n\\nAuthor: ...</td>\n",
       "      <td>AN</td>\n",
       "      <td>\\n\\nTitle: \\n\\nAuthor: \\n\\nRelease Date: Septe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AlmadaNegreiros0.txt</td>\n",
       "      <td>Title: A Scena do Odio\\n\\nAuthor: José de Alma...</td>\n",
       "      <td>AN</td>\n",
       "      <td>Title: \\n\\nAuthor: \\n\\nRelease Date: September...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AlmadaNegreiros1.txt</td>\n",
       "      <td>Title: O Jardim da Pierrette\\n\\nAuthor: José d...</td>\n",
       "      <td>AN</td>\n",
       "      <td>Title: \\n\\nAuthor: \\n\\nRelease Date: September...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AlmadaNegreiros5.txt</td>\n",
       "      <td>\\n\\n*JOSÉ DE ALMADA-NEGREIROS*\\n\\n\\n*K4\\n\\no q...</td>\n",
       "      <td>AN</td>\n",
       "      <td>\\n\\n**\\n\\n\\n*K4\\n\\no quadrado\\n\\nAZUL*\\n\\nACAB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               text  \\\n",
       "0  AlmadaNegreiros3.txt  \\nTitle: Litoral\\n       A Amadeo de Souza Car...   \n",
       "1  AlmadaNegreiros2.txt  \\n\\nTitle: A Invenção do Dia Claro\\n\\nAuthor: ...   \n",
       "2  AlmadaNegreiros0.txt  Title: A Scena do Odio\\n\\nAuthor: José de Alma...   \n",
       "3  AlmadaNegreiros1.txt  Title: O Jardim da Pierrette\\n\\nAuthor: José d...   \n",
       "4  AlmadaNegreiros5.txt  \\n\\n*JOSÉ DE ALMADA-NEGREIROS*\\n\\n\\n*K4\\n\\no q...   \n",
       "\n",
       "  author                                     removeMetadata  \n",
       "0     AN  \\nTitle: \\n       \\n\\nAuthor: \\n\\nContributor:...  \n",
       "1     AN  \\n\\nTitle: \\n\\nAuthor: \\n\\nRelease Date: Septe...  \n",
       "2     AN  Title: \\n\\nAuthor: \\n\\nRelease Date: September...  \n",
       "3     AN  Title: \\n\\nAuthor: \\n\\nRelease Date: September...  \n",
       "4     AN  \\n\\n**\\n\\n\\n*K4\\n\\no quadrado\\n\\nAZUL*\\n\\nACAB...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"clearTexts\">\n",
    "\n",
    "### 1.4. Cleaning Texts\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from tqdm import tqdm_notebook as tqdm #progressbar\n",
    "from unidecode import unidecode\n",
    "from nltk.stem import RSLPStemmer\n",
    "#nltk.download('rslp')\n",
    "\n",
    "#spacy tools\n",
    "import pt_core_news_sm\n",
    "import spacy\n",
    "spacy_nlp = spacy.load('pt_core_news_sm')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary functions for preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercasing(text):       \n",
    "    text = text.lower()     \n",
    "    return text\n",
    "\n",
    "def to_string(text):\n",
    "    text = text.split()\n",
    "    return text\n",
    "\n",
    "def lemmatization(word):\n",
    "    lem = WordNetLemmatizer()\n",
    "    word =lem.lemmatize(word)\n",
    "    return word\n",
    "\n",
    "def punctuation(word):\n",
    "    word = re.sub('[\\“\\”\\ \"\\-\\'`~!@#$%^&*()_|+=?;:,.<>\\{\\}\\[\\]\\\\\\/]','', word)\n",
    "    return word\n",
    "\n",
    "def stopwords_nltk(word):\n",
    "    stop_words = set(stopwords.words(\"portuguese\")) \n",
    "    return word in stop_words\n",
    "\n",
    "def stopwords_spacy(word):\n",
    "    return spacy_nlp.vocab[word].is_stop\n",
    "\n",
    "def accents(word):\n",
    "    word = unidecode(word)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing 1\n",
    "##### with punctuation and no lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_with_punc(doc, column):\n",
    "    processed_corpus = []\n",
    "    for i in tqdm(range(len(doc))):\n",
    "        text = doc[column].iloc[i,]    \n",
    "    \n",
    "        text = lowercasing(text)\n",
    "        \n",
    "        text = to_string(text)\n",
    "\n",
    "        textfinal = []\n",
    "        for word in text:\n",
    "            if stopwords_nltk(punctuation(word)) or stopwords_spacy(punctuation(word)):\n",
    "                word = re.sub('[^\\“\\”\\ \"\\-\\'`~!@#$%^&*()_|+=?;:,.<>\\{\\}\\[\\]\\\\\\/]','', word)\n",
    "            else:\n",
    "                word\n",
    "            textfinal.append(word)\n",
    "\n",
    "        text = \" \".join(textfinal)\n",
    "    \n",
    "        processed_corpus.append(text)\n",
    "         \n",
    "    return processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8dbb2cd6d545e99aa95270f08160f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=63.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1609ebac78514c3da054d9f721b61eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#this process takes some time, please have patience\n",
    "traindf['clean_with_punc'] = preprocessing_with_punc(traindf, 'removeMetadata')\n",
    "testdf['clean_with_punc'] = preprocessing_with_punc(testdf, 'removeMetadata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing 2 \n",
    "##### no punctuation and no lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_no_punc(doc, column):\n",
    "    processed_corpus = []\n",
    "    for i in tqdm(range(len(doc))):\n",
    "        text = doc[column].iloc[i,]    \n",
    "    \n",
    "        text = lowercasing(text)\n",
    "        \n",
    "        text = to_string(text)\n",
    "        \n",
    "        text = [punctuation(word) for word in text]\n",
    "\n",
    "        text = [word for word in text if (not stopwords_nltk(word)) and (not stopwords_spacy(word))]\n",
    "        \n",
    "        text = [accents(word) for word in text] \n",
    "\n",
    "        text = \" \".join(text)\n",
    "    \n",
    "        processed_corpus.append(text)\n",
    "         \n",
    "    return processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a044e93d23354680a613324e93474597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=63.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e530b1d982b482484228aa7af20fdb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "traindf['clean_no_punc'] = preprocessing_no_punc(traindf, 'removeMetadata')\n",
    "testdf['clean_no_punc'] = preprocessing_no_punc(testdf, 'removeMetadata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing the text into chunks of 500 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this process is kept as increasing the number of inputs into the model will help us increase its quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_doc(doc,column,n):\n",
    "    newdf = pd.DataFrame()\n",
    "    newdf = newdf.reindex(columns = ['id','chunks','author']) \n",
    "    for i in tqdm(range(len(doc))):\n",
    "        text = doc[column].iloc[i,]\n",
    "\n",
    "        text = text.split()\n",
    "\n",
    "        chunks = [' '.join(text[j:j+n]) for j in range(0,len(text),n)]\n",
    "\n",
    "        for c in chunks:\n",
    "            data = []\n",
    "            values = [doc['id'].iloc[i,], c, doc['author'].iloc[i,]]\n",
    "            a_dictionary = dict(zip(newdf.columns.tolist(), values))\n",
    "            data.append(a_dictionary)\n",
    "            newdf = newdf.append(data)\n",
    "            \n",
    "    newdf.index =[j for j in range(len(newdf))]  \n",
    "              \n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1061f4b1d942109d7013036e952518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=63.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "traindf_chunks = split_doc(traindf, 'clean_no_punc' ,500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.utils import np_utils\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/susanapaco/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing, tokening, tokenizing...\n",
      "Pre-processing - Train\n",
      "Pre-processing - test ...\n",
      "Keep Preprocessing...\n",
      "modelling!!!!!!!! \n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 64)            135296    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 168,710\n",
      "Trainable params: 168,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.4897 - accuracy: 0.3150\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.2954 - accuracy: 0.4266\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.0063 - accuracy: 0.5476\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.9172 - accuracy: 0.5931\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.8203 - accuracy: 0.6449\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.7222 - accuracy: 0.7119\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.6436 - accuracy: 0.7526\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.5749 - accuracy: 0.7808\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.5085 - accuracy: 0.8096\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.4898 - accuracy: 0.8235\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.4667 - accuracy: 0.8305\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.4303 - accuracy: 0.8484\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.3965 - accuracy: 0.8633\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.3889 - accuracy: 0.8572\n",
      "Epoch 15/100\n",
      " - 2s - loss: 0.3536 - accuracy: 0.8820\n",
      "Epoch 16/100\n",
      " - 2s - loss: 0.3286 - accuracy: 0.8869\n",
      "Epoch 17/100\n",
      " - 3s - loss: 0.3060 - accuracy: 0.8930\n",
      "Epoch 18/100\n",
      " - 3s - loss: 0.3020 - accuracy: 0.8927\n",
      "Epoch 19/100\n",
      " - 3s - loss: 0.2690 - accuracy: 0.9039\n",
      "Epoch 20/100\n",
      " - 3s - loss: 0.2636 - accuracy: 0.9093\n",
      "Epoch 21/100\n",
      " - 3s - loss: 0.2378 - accuracy: 0.9181\n",
      "Epoch 22/100\n",
      " - 2s - loss: 0.2523 - accuracy: 0.9118\n",
      "Epoch 23/100\n",
      " - 2s - loss: 0.2368 - accuracy: 0.9221\n",
      "Epoch 24/100\n",
      " - 2s - loss: 0.2252 - accuracy: 0.9221\n",
      "Epoch 25/100\n",
      " - 2s - loss: 0.2073 - accuracy: 0.9239\n",
      "Epoch 26/100\n",
      " - 2s - loss: 0.2020 - accuracy: 0.9306\n",
      "Epoch 27/100\n",
      " - 2s - loss: 0.1835 - accuracy: 0.9400\n",
      "Epoch 28/100\n",
      " - 2s - loss: 0.1703 - accuracy: 0.9421\n",
      "Epoch 29/100\n",
      " - 2s - loss: 0.1819 - accuracy: 0.9360\n",
      "Epoch 30/100\n",
      " - 2s - loss: 0.1694 - accuracy: 0.9427\n",
      "Epoch 31/100\n",
      " - 3s - loss: 0.1564 - accuracy: 0.9485\n",
      "Epoch 32/100\n",
      " - 2s - loss: 0.1534 - accuracy: 0.9448\n",
      "Epoch 33/100\n",
      " - 2s - loss: 0.1497 - accuracy: 0.9491\n",
      "Epoch 34/100\n",
      " - 2s - loss: 0.1538 - accuracy: 0.9466\n",
      "Epoch 35/100\n",
      " - 3s - loss: 0.1476 - accuracy: 0.9524\n",
      "Epoch 36/100\n",
      " - 2s - loss: 0.1445 - accuracy: 0.9524\n",
      "Epoch 37/100\n",
      " - 2s - loss: 0.1316 - accuracy: 0.9551\n",
      "Epoch 38/100\n",
      " - 3s - loss: 0.1235 - accuracy: 0.9563\n",
      "Epoch 39/100\n",
      " - 2s - loss: 0.1246 - accuracy: 0.9594\n",
      "Epoch 40/100\n",
      " - 2s - loss: 0.1147 - accuracy: 0.9618\n",
      "Epoch 41/100\n",
      " - 2s - loss: 0.1170 - accuracy: 0.9582\n",
      "Epoch 42/100\n",
      " - 2s - loss: 0.0892 - accuracy: 0.9712\n",
      "Epoch 43/100\n",
      " - 3s - loss: 0.0994 - accuracy: 0.9691\n",
      "Epoch 44/100\n",
      " - 2s - loss: 0.0957 - accuracy: 0.9676\n",
      "Epoch 45/100\n",
      " - 2s - loss: 0.1100 - accuracy: 0.9639\n",
      "Epoch 46/100\n",
      " - 2s - loss: 0.0962 - accuracy: 0.9654\n",
      "Epoch 47/100\n",
      " - 3s - loss: 0.0891 - accuracy: 0.9703\n",
      "Epoch 48/100\n",
      " - 2s - loss: 0.0948 - accuracy: 0.9694\n",
      "Epoch 49/100\n",
      " - 2s - loss: 0.0728 - accuracy: 0.9754\n",
      "Epoch 50/100\n",
      " - 2s - loss: 0.0850 - accuracy: 0.9724\n",
      "Epoch 51/100\n",
      " - 2s - loss: 0.0720 - accuracy: 0.9779\n",
      "Epoch 52/100\n",
      " - 2s - loss: 0.0811 - accuracy: 0.9718\n",
      "Epoch 53/100\n",
      " - 2s - loss: 0.0759 - accuracy: 0.9770\n",
      "Epoch 54/100\n",
      " - 2s - loss: 0.0791 - accuracy: 0.9703\n",
      "Epoch 55/100\n",
      " - 2s - loss: 0.0804 - accuracy: 0.9751\n",
      "Epoch 56/100\n",
      " - 2s - loss: 0.0723 - accuracy: 0.9739\n",
      "Epoch 57/100\n",
      " - 3s - loss: 0.0712 - accuracy: 0.9770\n",
      "Epoch 58/100\n",
      " - 3s - loss: 0.0690 - accuracy: 0.9800\n",
      "Epoch 59/100\n",
      " - 2s - loss: 0.0650 - accuracy: 0.9782\n",
      "Epoch 60/100\n",
      " - 2s - loss: 0.0777 - accuracy: 0.9745\n",
      "Epoch 61/100\n",
      " - 2s - loss: 0.0644 - accuracy: 0.9812\n",
      "Epoch 62/100\n",
      " - 2s - loss: 0.0552 - accuracy: 0.9815\n",
      "Epoch 63/100\n",
      " - 2s - loss: 0.0679 - accuracy: 0.9776\n",
      "Epoch 64/100\n",
      " - 2s - loss: 0.0526 - accuracy: 0.9812\n",
      "Epoch 65/100\n",
      " - 3s - loss: 0.0497 - accuracy: 0.9839\n",
      "Epoch 66/100\n",
      " - 2s - loss: 0.0691 - accuracy: 0.9782\n",
      "Epoch 67/100\n",
      " - 2s - loss: 0.0591 - accuracy: 0.9818\n",
      "Epoch 68/100\n",
      " - 2s - loss: 0.0526 - accuracy: 0.9833\n",
      "Epoch 69/100\n",
      " - 2s - loss: 0.0518 - accuracy: 0.9839\n",
      "Epoch 70/100\n",
      " - 2s - loss: 0.0508 - accuracy: 0.9824\n",
      "Epoch 71/100\n",
      " - 2s - loss: 0.0530 - accuracy: 0.9833\n",
      "Epoch 72/100\n",
      " - 3s - loss: 0.0522 - accuracy: 0.9842\n",
      "Epoch 73/100\n",
      " - 3s - loss: 0.0527 - accuracy: 0.9839\n",
      "Epoch 74/100\n",
      " - 3s - loss: 0.0496 - accuracy: 0.9857\n",
      "Epoch 75/100\n",
      " - 2s - loss: 0.0602 - accuracy: 0.9782\n",
      "Epoch 76/100\n",
      " - 2s - loss: 0.0479 - accuracy: 0.9842\n",
      "Epoch 77/100\n",
      " - 2s - loss: 0.0515 - accuracy: 0.9815\n",
      "Epoch 78/100\n",
      " - 2s - loss: 0.0551 - accuracy: 0.9806\n",
      "Epoch 79/100\n",
      " - 3s - loss: 0.0360 - accuracy: 0.9873\n",
      "Epoch 80/100\n",
      " - 3s - loss: 0.0480 - accuracy: 0.9824\n",
      "Epoch 81/100\n",
      " - 2s - loss: 0.0486 - accuracy: 0.9851\n",
      "Epoch 82/100\n",
      " - 2s - loss: 0.0393 - accuracy: 0.9861\n",
      "Epoch 83/100\n",
      " - 3s - loss: 0.0360 - accuracy: 0.9870\n",
      "Epoch 84/100\n",
      " - 2s - loss: 0.0331 - accuracy: 0.9900\n",
      "Epoch 85/100\n",
      " - 2s - loss: 0.0439 - accuracy: 0.9842\n",
      "Epoch 86/100\n",
      " - 2s - loss: 0.0404 - accuracy: 0.9891\n",
      "Epoch 87/100\n",
      " - 2s - loss: 0.0365 - accuracy: 0.9870\n",
      "Epoch 88/100\n",
      " - 2s - loss: 0.0384 - accuracy: 0.9873\n",
      "Epoch 89/100\n",
      " - 2s - loss: 0.0370 - accuracy: 0.9870\n",
      "Epoch 90/100\n",
      " - 2s - loss: 0.0473 - accuracy: 0.9827\n",
      "Epoch 91/100\n",
      " - 2s - loss: 0.0289 - accuracy: 0.9915\n",
      "Epoch 92/100\n",
      " - 2s - loss: 0.0425 - accuracy: 0.9873\n",
      "Epoch 93/100\n",
      " - 2s - loss: 0.0334 - accuracy: 0.9876\n",
      "Epoch 94/100\n",
      " - 3s - loss: 0.0338 - accuracy: 0.9903\n",
      "Epoch 95/100\n",
      " - 3s - loss: 0.0309 - accuracy: 0.9918\n",
      "Epoch 96/100\n",
      " - 3s - loss: 0.0386 - accuracy: 0.9861\n",
      "Epoch 97/100\n",
      " - 3s - loss: 0.0386 - accuracy: 0.9854\n",
      "Epoch 98/100\n",
      " - 2s - loss: 0.0350 - accuracy: 0.9876\n",
      "Epoch 99/100\n",
      " - 2s - loss: 0.0339 - accuracy: 0.9885\n",
      "Epoch 100/100\n",
      " - 2s - loss: 0.0254 - accuracy: 0.9933\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'float' and 'builtin_function_or_method'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-abf4be433d23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m# Print f1, precision, and recall scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \"\"\"\n\u001b[0;32m-> 1186\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'float' and 'builtin_function_or_method'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Tokenize sentences\n",
    "print(\"Tokenizing, tokening, tokenizing...\")\n",
    "#1. Train set\n",
    "text_list_train = list(traindf_chunks['chunks'])\n",
    "#text_list_train_lower = [word.lower() for word in text_list_train]\n",
    "tokenized_text_train = [word_tokenize(i) for i in text_list_train]\n",
    "\n",
    "#2. Test set\n",
    "text_list_test = list(testdf['clean_no_punc'])\n",
    "#text_list_test_lower = [word.lower() for word in text_list_test]\n",
    "tokenized_text_test = [word_tokenize(i) for i in text_list_test]\n",
    "\n",
    "#Create vocabulary from train set only\n",
    "list_of_all_words= list(itertools.chain.from_iterable(tokenized_text_test))\n",
    "vocabulary =sorted(list(set(list_of_all_words)))\n",
    "\n",
    "#Remove stopwords (I found out that it makes no difference but you can try on your own)\n",
    "#vocabulary = [word for word in vocabulary if word not in stopwords.words('english')]\n",
    "\n",
    "#--------------------------Pre-processing train and test sets----------------------------------\n",
    "print('Pre-processing - Train')\n",
    "tokenized_numbers_train = copy.deepcopy(tokenized_text_train)\n",
    "\n",
    "i=-1\n",
    "for list in tokenized_numbers_train:\n",
    "    i=i+1\n",
    "    j=-1\n",
    "    for number in list:\n",
    "        j = j + 1\n",
    "        if tokenized_numbers_train[i][j] in vocabulary:\n",
    "            tokenized_numbers_train[i][j]= vocabulary.index(number)\n",
    "        else:\n",
    "            tokenized_numbers_train[i][j] = 0\n",
    "\n",
    "tokens_train = pd.DataFrame(tokenized_numbers_train, dtype='int32')\n",
    "tokens_train = tokens_train.fillna(0)\n",
    "tokens_train = tokens_train.astype(int)\n",
    "\n",
    "print('Pre-processing - test ...')\n",
    "tokenized_numbers_test = copy.deepcopy(tokenized_text_test)\n",
    "\n",
    "i=-1\n",
    "for list in tokenized_numbers_test:\n",
    "    i=i+1\n",
    "    j=-1\n",
    "    for number in list:\n",
    "        j = j + 1\n",
    "        if tokenized_numbers_test[i][j] in vocabulary:\n",
    "            tokenized_numbers_test[i][j] = vocabulary.index(number)\n",
    "        else:\n",
    "            tokenized_numbers_test[i][j] = 0\n",
    "\n",
    "tokens_test = pd.DataFrame(tokenized_numbers_test, dtype='int32')\n",
    "tokens_test = tokens_test.fillna(0)\n",
    "tokens_test = tokens_test.astype(int)\n",
    "\n",
    "print('Keep Preprocessing...')\n",
    "\n",
    "#Bring both sets to same shape (Choose how many words to use)\n",
    "max_words_in_sentence=30\n",
    "\n",
    "#Shorten or extend Train set to reach selected length\n",
    "if tokens_train.shape[1]>max_words_in_sentence:\n",
    "    tokens_train = tokens_train.drop(tokens_train.columns[[range(max_words_in_sentence,tokens_train.shape[1])]], axis=1)\n",
    "else:\n",
    "    for col in range(tokens_train.shape[1],max_words_in_sentence):\n",
    "        tokens_train[col]=0\n",
    "\n",
    "#Shorten or extend Test set to reach selected length\n",
    "if tokens_test.shape[1] > max_words_in_sentence:\n",
    "    tokens_test = tokens_test.drop(tokens_test.columns[[range(max_words_in_sentence, tokens_test.shape[1])]],\n",
    "                                     axis=1)\n",
    "else:\n",
    "    for col in range(tokens_test.shape[1], max_words_in_sentence):\n",
    "        tokens_test[col] = 0\n",
    "\n",
    "#------------------------------Finish Pre-processing----------------------------------------------------\n",
    "\n",
    "#Define train and Test sets\n",
    "train_x = np.array(tokens_train)\n",
    "train_y = np.array(traindf_chunks['author'])\n",
    "\n",
    "test_x = np.array(tokens_test)\n",
    "\n",
    "encoder1 = LabelEncoder()\n",
    "encoder1.fit(train_y)\n",
    "encoded_train_Y = encoder1.transform(train_y)\n",
    "dummy_train_y = np_utils.to_categorical(encoded_train_Y)\n",
    "dummy_train_y.astype(int)\n",
    "\n",
    "l=len(vocabulary)+1\n",
    "inp=train_x.shape[1]\n",
    "\n",
    "\n",
    "print (\"modelling!!!!!!!! \")\n",
    "#Build an LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(l, 64,input_length=inp))\n",
    "model.add(LSTM(64, dropout=0.4, recurrent_dropout=0.1))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# Fit the model\n",
    "model.fit(train_x, dummy_train_y, epochs=100, batch_size=16, verbose=2)\n",
    "\n",
    "\n",
    "\n",
    "# Predict and write to file\n",
    "results = model.predict(test_x)\n",
    "results = pd.DataFrame(results, columns=['AN','CCB','EQ','JRS','JS','LMS'])\n",
    "results['prediction'] = results[['AN','CCB','EQ','JRS','JS','LMS']].idxmax(axis=1)\n",
    "results ['possibleresult'] = testdf['possibleanswer']\n",
    "results.insert(0, \"id\", id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3298/3298 [==============================] - 0s 126us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0056771598697717375, 0.9987871646881104]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_x, dummy_train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>AN</th>\n",
       "      <th>CCB</th>\n",
       "      <th>EQ</th>\n",
       "      <th>JRS</th>\n",
       "      <th>JS</th>\n",
       "      <th>LMS</th>\n",
       "      <th>prediction</th>\n",
       "      <th>possibleresult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;built-in function id&gt;</td>\n",
       "      <td>2.211483e-09</td>\n",
       "      <td>1.256220e-06</td>\n",
       "      <td>3.181956e-07</td>\n",
       "      <td>9.999974e-01</td>\n",
       "      <td>1.086299e-06</td>\n",
       "      <td>1.476060e-08</td>\n",
       "      <td>JRS</td>\n",
       "      <td>JRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;built-in function id&gt;</td>\n",
       "      <td>2.076855e-05</td>\n",
       "      <td>9.997914e-01</td>\n",
       "      <td>1.472466e-04</td>\n",
       "      <td>1.721187e-05</td>\n",
       "      <td>2.345431e-05</td>\n",
       "      <td>5.879558e-08</td>\n",
       "      <td>CCB</td>\n",
       "      <td>CCB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;built-in function id&gt;</td>\n",
       "      <td>8.248107e-05</td>\n",
       "      <td>4.223248e-05</td>\n",
       "      <td>9.998560e-01</td>\n",
       "      <td>1.571103e-06</td>\n",
       "      <td>1.776126e-05</td>\n",
       "      <td>1.933465e-08</td>\n",
       "      <td>EQ</td>\n",
       "      <td>EQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;built-in function id&gt;</td>\n",
       "      <td>2.144518e-11</td>\n",
       "      <td>3.779560e-10</td>\n",
       "      <td>5.657661e-09</td>\n",
       "      <td>1.447884e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.161688e-08</td>\n",
       "      <td>JS</td>\n",
       "      <td>JS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;built-in function id&gt;</td>\n",
       "      <td>2.172659e-09</td>\n",
       "      <td>6.690935e-07</td>\n",
       "      <td>6.178995e-06</td>\n",
       "      <td>9.999861e-01</td>\n",
       "      <td>7.172130e-06</td>\n",
       "      <td>2.350891e-08</td>\n",
       "      <td>JRS</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;built-in function id&gt;</td>\n",
       "      <td>1.487159e-09</td>\n",
       "      <td>9.999983e-01</td>\n",
       "      <td>2.158333e-07</td>\n",
       "      <td>1.037186e-06</td>\n",
       "      <td>3.375156e-07</td>\n",
       "      <td>1.866445e-10</td>\n",
       "      <td>CCB</td>\n",
       "      <td>AN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;built-in function id&gt;</td>\n",
       "      <td>2.211483e-09</td>\n",
       "      <td>1.256220e-06</td>\n",
       "      <td>3.181956e-07</td>\n",
       "      <td>9.999974e-01</td>\n",
       "      <td>1.086299e-06</td>\n",
       "      <td>1.476060e-08</td>\n",
       "      <td>JRS</td>\n",
       "      <td>JRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;built-in function id&gt;</td>\n",
       "      <td>2.076855e-05</td>\n",
       "      <td>9.997914e-01</td>\n",
       "      <td>1.472466e-04</td>\n",
       "      <td>1.721187e-05</td>\n",
       "      <td>2.345431e-05</td>\n",
       "      <td>5.879558e-08</td>\n",
       "      <td>CCB</td>\n",
       "      <td>CCB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;built-in function id&gt;</td>\n",
       "      <td>8.248107e-05</td>\n",
       "      <td>4.223248e-05</td>\n",
       "      <td>9.998560e-01</td>\n",
       "      <td>1.571103e-06</td>\n",
       "      <td>1.776126e-05</td>\n",
       "      <td>1.933465e-08</td>\n",
       "      <td>EQ</td>\n",
       "      <td>EQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;built-in function id&gt;</td>\n",
       "      <td>2.144518e-11</td>\n",
       "      <td>3.779560e-10</td>\n",
       "      <td>5.657661e-09</td>\n",
       "      <td>1.447884e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.161688e-08</td>\n",
       "      <td>JS</td>\n",
       "      <td>JS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;built-in function id&gt;</td>\n",
       "      <td>2.172659e-09</td>\n",
       "      <td>6.690935e-07</td>\n",
       "      <td>6.178995e-06</td>\n",
       "      <td>9.999861e-01</td>\n",
       "      <td>7.172130e-06</td>\n",
       "      <td>2.350891e-08</td>\n",
       "      <td>JRS</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;built-in function id&gt;</td>\n",
       "      <td>1.487159e-09</td>\n",
       "      <td>9.999983e-01</td>\n",
       "      <td>2.158333e-07</td>\n",
       "      <td>1.037186e-06</td>\n",
       "      <td>3.375156e-07</td>\n",
       "      <td>1.866445e-10</td>\n",
       "      <td>CCB</td>\n",
       "      <td>AN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id            AN           CCB            EQ  \\\n",
       "0   <built-in function id>  2.211483e-09  1.256220e-06  3.181956e-07   \n",
       "1   <built-in function id>  2.076855e-05  9.997914e-01  1.472466e-04   \n",
       "2   <built-in function id>  8.248107e-05  4.223248e-05  9.998560e-01   \n",
       "3   <built-in function id>  2.144518e-11  3.779560e-10  5.657661e-09   \n",
       "4   <built-in function id>  2.172659e-09  6.690935e-07  6.178995e-06   \n",
       "5   <built-in function id>  1.487159e-09  9.999983e-01  2.158333e-07   \n",
       "6   <built-in function id>  2.211483e-09  1.256220e-06  3.181956e-07   \n",
       "7   <built-in function id>  2.076855e-05  9.997914e-01  1.472466e-04   \n",
       "8   <built-in function id>  8.248107e-05  4.223248e-05  9.998560e-01   \n",
       "9   <built-in function id>  2.144518e-11  3.779560e-10  5.657661e-09   \n",
       "10  <built-in function id>  2.172659e-09  6.690935e-07  6.178995e-06   \n",
       "11  <built-in function id>  1.487159e-09  9.999983e-01  2.158333e-07   \n",
       "\n",
       "             JRS            JS           LMS prediction possibleresult  \n",
       "0   9.999974e-01  1.086299e-06  1.476060e-08        JRS            JRS  \n",
       "1   1.721187e-05  2.345431e-05  5.879558e-08        CCB            CCB  \n",
       "2   1.571103e-06  1.776126e-05  1.933465e-08         EQ             EQ  \n",
       "3   1.447884e-09  1.000000e+00  5.161688e-08         JS             JS  \n",
       "4   9.999861e-01  7.172130e-06  2.350891e-08        JRS        unknown  \n",
       "5   1.037186e-06  3.375156e-07  1.866445e-10        CCB             AN  \n",
       "6   9.999974e-01  1.086299e-06  1.476060e-08        JRS            JRS  \n",
       "7   1.721187e-05  2.345431e-05  5.879558e-08        CCB            CCB  \n",
       "8   1.571103e-06  1.776126e-05  1.933465e-08         EQ             EQ  \n",
       "9   1.447884e-09  1.000000e+00  5.161688e-08         JS             JS  \n",
       "10  9.999861e-01  7.172130e-06  2.350891e-08        JRS        unknown  \n",
       "11  1.037186e-06  3.375156e-07  1.866445e-10        CCB             AN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and Loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 3s - loss: 0.0362 - accuracy: 0.9876\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.0268 - accuracy: 0.9924\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.0307 - accuracy: 0.9900\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.0365 - accuracy: 0.9879\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.0268 - accuracy: 0.9903\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.0329 - accuracy: 0.9891\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0301 - accuracy: 0.9900\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0338 - accuracy: 0.9891\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0337 - accuracy: 0.9900\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.0380 - accuracy: 0.9870\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.0316 - accuracy: 0.9912\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.0302 - accuracy: 0.9912\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.0294 - accuracy: 0.9915\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.0319 - accuracy: 0.9900\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.0294 - accuracy: 0.9906\n",
      "Epoch 16/100\n",
      " - 3s - loss: 0.0210 - accuracy: 0.9945\n",
      "Epoch 17/100\n",
      " - 3s - loss: 0.0225 - accuracy: 0.9927\n",
      "Epoch 18/100\n",
      " - 3s - loss: 0.0224 - accuracy: 0.9936\n",
      "Epoch 19/100\n",
      " - 3s - loss: 0.0157 - accuracy: 0.9958\n",
      "Epoch 20/100\n",
      " - 3s - loss: 0.0174 - accuracy: 0.9955\n",
      "Epoch 21/100\n",
      " - 3s - loss: 0.0270 - accuracy: 0.9912\n",
      "Epoch 22/100\n",
      " - 3s - loss: 0.0273 - accuracy: 0.9897\n",
      "Epoch 23/100\n",
      " - 3s - loss: 0.0246 - accuracy: 0.9924\n",
      "Epoch 24/100\n",
      " - 3s - loss: 0.0278 - accuracy: 0.9912\n",
      "Epoch 25/100\n",
      " - 3s - loss: 0.0216 - accuracy: 0.9939\n",
      "Epoch 26/100\n",
      " - 3s - loss: 0.0239 - accuracy: 0.9918\n",
      "Epoch 27/100\n",
      " - 3s - loss: 0.0261 - accuracy: 0.9918\n",
      "Epoch 28/100\n",
      " - 3s - loss: 0.0180 - accuracy: 0.9948\n",
      "Epoch 29/100\n",
      " - 3s - loss: 0.0233 - accuracy: 0.9918\n",
      "Epoch 30/100\n",
      " - 3s - loss: 0.0191 - accuracy: 0.9936\n",
      "Epoch 31/100\n",
      " - 3s - loss: 0.0181 - accuracy: 0.9945\n",
      "Epoch 32/100\n",
      " - 3s - loss: 0.0261 - accuracy: 0.9912\n",
      "Epoch 33/100\n",
      " - 3s - loss: 0.0141 - accuracy: 0.9967\n",
      "Epoch 34/100\n",
      " - 3s - loss: 0.0210 - accuracy: 0.9942\n",
      "Epoch 35/100\n",
      " - 3s - loss: 0.0273 - accuracy: 0.9921\n",
      "Epoch 36/100\n",
      " - 3s - loss: 0.0230 - accuracy: 0.9903\n",
      "Epoch 37/100\n",
      " - 3s - loss: 0.0190 - accuracy: 0.9942\n",
      "Epoch 38/100\n",
      " - 3s - loss: 0.0163 - accuracy: 0.9945\n",
      "Epoch 39/100\n",
      " - 3s - loss: 0.0185 - accuracy: 0.9936\n",
      "Epoch 40/100\n",
      " - 3s - loss: 0.0224 - accuracy: 0.9927\n",
      "Epoch 41/100\n",
      " - 3s - loss: 0.0206 - accuracy: 0.9930\n",
      "Epoch 42/100\n",
      " - 3s - loss: 0.0180 - accuracy: 0.9945\n",
      "Epoch 43/100\n",
      " - 3s - loss: 0.0254 - accuracy: 0.9918\n",
      "Epoch 44/100\n",
      " - 3s - loss: 0.0155 - accuracy: 0.9948\n",
      "Epoch 45/100\n",
      " - 3s - loss: 0.0192 - accuracy: 0.9924\n",
      "Epoch 46/100\n",
      " - 3s - loss: 0.0192 - accuracy: 0.9942\n",
      "Epoch 47/100\n",
      " - 3s - loss: 0.0218 - accuracy: 0.9915\n",
      "Epoch 48/100\n",
      " - 3s - loss: 0.0140 - accuracy: 0.9955\n",
      "Epoch 49/100\n",
      " - 3s - loss: 0.0146 - accuracy: 0.9948\n",
      "Epoch 50/100\n",
      " - 3s - loss: 0.0196 - accuracy: 0.9936\n",
      "Epoch 51/100\n",
      " - 3s - loss: 0.0226 - accuracy: 0.9933\n",
      "Epoch 52/100\n",
      " - 3s - loss: 0.0141 - accuracy: 0.9958\n",
      "Epoch 53/100\n",
      " - 3s - loss: 0.0215 - accuracy: 0.9921\n",
      "Epoch 54/100\n",
      " - 3s - loss: 0.0177 - accuracy: 0.9955\n",
      "Epoch 55/100\n",
      " - 3s - loss: 0.0182 - accuracy: 0.9942\n",
      "Epoch 56/100\n",
      " - 3s - loss: 0.0166 - accuracy: 0.9948\n",
      "Epoch 57/100\n",
      " - 3s - loss: 0.0102 - accuracy: 0.9970\n",
      "Epoch 58/100\n",
      " - 3s - loss: 0.0168 - accuracy: 0.9942\n",
      "Epoch 59/100\n",
      " - 3s - loss: 0.0183 - accuracy: 0.9939\n",
      "Epoch 60/100\n",
      " - 3s - loss: 0.0197 - accuracy: 0.9933\n",
      "Epoch 61/100\n",
      " - 3s - loss: 0.0160 - accuracy: 0.9955\n",
      "Epoch 62/100\n",
      " - 3s - loss: 0.0253 - accuracy: 0.9912\n",
      "Epoch 63/100\n",
      " - 3s - loss: 0.0188 - accuracy: 0.9936\n",
      "Epoch 64/100\n",
      " - 3s - loss: 0.0121 - accuracy: 0.9958\n",
      "Epoch 65/100\n",
      " - 3s - loss: 0.0130 - accuracy: 0.9961\n",
      "Epoch 66/100\n",
      " - 3s - loss: 0.0181 - accuracy: 0.9951\n",
      "Epoch 67/100\n",
      " - 3s - loss: 0.0123 - accuracy: 0.9955\n",
      "Epoch 68/100\n",
      " - 3s - loss: 0.0091 - accuracy: 0.9967\n",
      "Epoch 69/100\n",
      " - 3s - loss: 0.0156 - accuracy: 0.9955\n",
      "Epoch 70/100\n",
      " - 3s - loss: 0.0252 - accuracy: 0.9921\n",
      "Epoch 71/100\n",
      " - 3s - loss: 0.0139 - accuracy: 0.9955\n",
      "Epoch 72/100\n",
      " - 3s - loss: 0.0140 - accuracy: 0.9948\n",
      "Epoch 73/100\n",
      " - 3s - loss: 0.0167 - accuracy: 0.9945\n",
      "Epoch 74/100\n",
      " - 3s - loss: 0.0133 - accuracy: 0.9958\n",
      "Epoch 75/100\n",
      " - 3s - loss: 0.0125 - accuracy: 0.9948\n",
      "Epoch 76/100\n",
      " - 3s - loss: 0.0122 - accuracy: 0.9958\n",
      "Epoch 77/100\n",
      " - 3s - loss: 0.0132 - accuracy: 0.9964\n",
      "Epoch 78/100\n",
      " - 3s - loss: 0.0140 - accuracy: 0.9951\n",
      "Epoch 79/100\n",
      " - 3s - loss: 0.0133 - accuracy: 0.9967\n",
      "Epoch 80/100\n",
      " - 3s - loss: 0.0215 - accuracy: 0.9945\n",
      "Epoch 81/100\n",
      " - 3s - loss: 0.0112 - accuracy: 0.9973\n",
      "Epoch 82/100\n",
      " - 3s - loss: 0.0053 - accuracy: 0.9991\n",
      "Epoch 83/100\n",
      " - 3s - loss: 0.0080 - accuracy: 0.9976\n",
      "Epoch 84/100\n",
      " - 3s - loss: 0.0118 - accuracy: 0.9961\n",
      "Epoch 85/100\n",
      " - 3s - loss: 0.0143 - accuracy: 0.9964\n",
      "Epoch 86/100\n",
      " - 3s - loss: 0.0113 - accuracy: 0.9970\n",
      "Epoch 87/100\n",
      " - 3s - loss: 0.0109 - accuracy: 0.9964\n",
      "Epoch 88/100\n",
      " - 3s - loss: 0.0147 - accuracy: 0.9948\n",
      "Epoch 89/100\n",
      " - 3s - loss: 0.0099 - accuracy: 0.9970\n",
      "Epoch 90/100\n",
      " - 3s - loss: 0.0148 - accuracy: 0.9961\n",
      "Epoch 91/100\n",
      " - 3s - loss: 0.0162 - accuracy: 0.9945\n",
      "Epoch 92/100\n",
      " - 3s - loss: 0.0088 - accuracy: 0.9973\n",
      "Epoch 93/100\n",
      " - 3s - loss: 0.0129 - accuracy: 0.9955\n",
      "Epoch 94/100\n",
      " - 3s - loss: 0.0129 - accuracy: 0.9961\n",
      "Epoch 95/100\n",
      " - 3s - loss: 0.0121 - accuracy: 0.9967\n",
      "Epoch 96/100\n",
      " - 3s - loss: 0.0106 - accuracy: 0.9958\n",
      "Epoch 97/100\n",
      " - 3s - loss: 0.0154 - accuracy: 0.9942\n",
      "Epoch 98/100\n",
      " - 3s - loss: 0.0129 - accuracy: 0.9958\n",
      "Epoch 99/100\n",
      " - 3s - loss: 0.0111 - accuracy: 0.9970\n",
      "Epoch 100/100\n",
      " - 3s - loss: 0.0109 - accuracy: 0.9970\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, dummy_train_y, epochs=100, batch_size=16, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(n_epochs, model):\n",
    "    loss = model.history['loss']\n",
    "    accuracy = model.history['accuracy']\n",
    "    epochs = range(1,(n_epochs + 1))\n",
    "    plt.plot(epochs, loss, 'g', label='loss')\n",
    "    plt.plot(epochs, accuracy, 'b', label='accuracy')\n",
    "    plt.title('Loss and Accuracy score')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Score')\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric(100,history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
